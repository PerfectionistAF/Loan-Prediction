{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d306523",
   "metadata": {},
   "source": [
    "# LOAN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20150693",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586bbab2",
   "metadata": {},
   "source": [
    "### Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec4c3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e424c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.read_csv(\"Train Data.csv\", delimiter = ',', header = 0, index_col = 0)\n",
    "#print(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f61c62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>600.00000</td>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>342.00000</td>\n",
       "      <td>0.842199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>85.587325</td>\n",
       "      <td>65.12041</td>\n",
       "      <td>0.364878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  592.000000         600.00000   \n",
       "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
       "std        6109.041673        2926.248369   85.587325          65.12041   \n",
       "min         150.000000           0.000000    9.000000          12.00000   \n",
       "25%        2877.500000           0.000000  100.000000         360.00000   \n",
       "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
       "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
       "max       81000.000000       41667.000000  700.000000         480.00000   \n",
       "\n",
       "       Credit_History  \n",
       "count      564.000000  \n",
       "mean         0.842199  \n",
       "std          0.364878  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the univariant statistics for numerical variables\n",
    "TrainData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d374df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married Dependents Education Self_Employed  ApplicantIncome  \\\n",
       "0   Male     Yes          0  Graduate            No             2500   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                0.0       120.0             360.0             1.0   \n",
       "\n",
       "  Property_Area Loan_Status  \n",
       "0     Semiurban           Y  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7341cd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">ApplicantIncome</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CoapplicantIncome</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Loan_Amount_Term</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Credit_History</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>192.0</td>\n",
       "      <td>5446.078125</td>\n",
       "      <td>6819.558528</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>3833.5</td>\n",
       "      <td>5861.25</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1877.807292</td>\n",
       "      <td>...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>422.0</td>\n",
       "      <td>5384.068720</td>\n",
       "      <td>5765.441615</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2877.5</td>\n",
       "      <td>3812.5</td>\n",
       "      <td>5771.50</td>\n",
       "      <td>63337.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1504.516398</td>\n",
       "      <td>...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.133782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ApplicantIncome                                                   \\\n",
       "                      count         mean          std    min     25%     50%   \n",
       "Loan_Status                                                                    \n",
       "N                     192.0  5446.078125  6819.558528  150.0  2885.0  3833.5   \n",
       "Y                     422.0  5384.068720  5765.441615  210.0  2877.5  3812.5   \n",
       "\n",
       "                              CoapplicantIncome               ...  \\\n",
       "                 75%      max             count         mean  ...   \n",
       "Loan_Status                                                   ...   \n",
       "N            5861.25  81000.0             192.0  1877.807292  ...   \n",
       "Y            5771.50  63337.0             422.0  1504.516398  ...   \n",
       "\n",
       "            Loan_Amount_Term        Credit_History                           \\\n",
       "                         75%    max          count      mean       std  min   \n",
       "Loan_Status                                                                   \n",
       "N                      360.0  480.0          179.0  0.541899  0.499639  0.0   \n",
       "Y                      360.0  480.0          385.0  0.981818  0.133782  0.0   \n",
       "\n",
       "                                 \n",
       "             25%  50%  75%  max  \n",
       "Loan_Status                      \n",
       "N            0.0  1.0  1.0  1.0  \n",
       "Y            1.0  1.0  1.0  1.0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the bivariant statistics between each variable with the Loan Status(Yes or No)\n",
    "TrainData.groupby(\"Loan_Status\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8b7e662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kurtosis: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      60.540676\n",
       "CoapplicantIncome    84.956384\n",
       "LoanAmount           10.401533\n",
       "Loan_Amount_Term      6.673474\n",
       "Credit_History        1.548763\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"kurtosis: \")\n",
    "TrainData.kurtosis(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "57ff475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skew: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      6.539513\n",
       "CoapplicantIncome    7.491531\n",
       "LoanAmount           2.677552\n",
       "Loan_Amount_Term    -2.362414\n",
       "Credit_History      -1.882361\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"skew: \")\n",
    "TrainData.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "35ff1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes!! Conclusions to KEEP IN MIND: \n",
    "# CoapplicantIncome: 25% is $0. Later, remove tuples where CoapplicantIncome=0 and analyze on its own.\n",
    "# Loan_Amount_term: Q1, Q2, Q3 = 360. Which means the data is skewed towards their favor. (360 months loan)\n",
    "# STD is pretty high for ApplicantIncome=6109 and CoapplicantIncome=2926\n",
    "# Credit_History: Q1, Q2, Q3 = 1. Which means that most people have credit history.\n",
    "# Note: very important to treat loan term and credit history as categorical, not numerical, since its values are discrete\n",
    "\n",
    "# skewness determines asymmetrical distribution\n",
    "# ¬∑ -0.5 < skewness < 0.5, the data are fairly symmetrical\n",
    "# ¬∑  -1 < skewness < ‚Äî 0.5 or  0.5 < skewness < 1, the data are moderately skewed\n",
    "# ¬∑ skewness < -1 or skewness > 1, the data are highly skewed\n",
    "\n",
    "# kurtosis determine the volume of the outlier\n",
    "# ¬∑ If the distribution is tall and thin it is called a leptokurtic distribution(Kurtosis > 3). Values in a leptokurtic distribution are near the mean or at the extremes.\n",
    "# ¬∑ A flat distribution where the values are moderately spread out (i.e., unlike leptokurtic) is called platykurtic(Kurtosis <3) distribution.\n",
    "# ¬∑ A distribution whose shape is in between a leptokurtic distribution and a platykurtic distribution is called a mesokurtic(Kurtosis=3) distribution. A mesokurtic distribution looks more close to a normal distribution.\n",
    "# source: https://medium.com/@atanudan/kurtosis-skew-function-in-pandas-aa63d72e20de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5eb8e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1546089f8e0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizing Numerical Features\n",
    "NumericData = TrainData.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "TrainData_n = TrainData[NumericData]\n",
    "#print(\"Description of Numerical Features:\", TrainData.describe()) \n",
    "\n",
    "\n",
    "# seaborn histograms (univariate and pairwise)\n",
    "# TODO tweak this so it looks better. try other things like scatter, density, histo, etc\n",
    "# TODO please look up how to visualize correlation with the TARGET\n",
    "# \"Numerical features can be visualized by plotting their distribution and having a look at their statistical properties, \n",
    "# such as skewness and kurtosis. For categorical features, the distribution is better visualized using histograms. \n",
    "# Finally, you can calculate and visualize the correlation between the features and also the features with the target value.\"\n",
    "# source: https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0\n",
    "# tutorial (ref doc): https://seaborn.pydata.org/tutorial/distributions.html\n",
    "# TODO please examine the correlation matrix results at the end of the notebook, \n",
    "# and draw a relational plot with the three most correlated values\n",
    "# tutorial: https://seaborn.pydata.org/tutorial/relational.html#relational-tutorial\n",
    "# Important note: this is a very general API. You can adjust more specifically by using jointplot, scatterplot etc.\n",
    "sns.pairplot(TrainData, hue = \"Loan_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2049a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Credit_History', ylabel='count'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizing Categorical Features\n",
    "#TODO use countplot to visualize univariate categorical\n",
    "sns.countplot(data=TrainData,\n",
    "    x=\"Credit_History\",\n",
    "    hue=\"Loan_Status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "810440a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Loan_Amount_Term', ylabel='count'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(data=TrainData,\n",
    "    x=\"Loan_Amount_Term\",\n",
    "    hue=\"Loan_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5a0197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x15462fc39a0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.displot(data=TrainData,\n",
    "    x=\"ApplicantIncome\", #y='ApplicantIncome',\n",
    "    hue=\"Loan_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb634acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x15465a13d00>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.displot(\n",
    "    data=TrainData, #kind =\"count\",\n",
    "    x=\"Married\" , hue=\"Loan_Status\"#, element=\"step\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd938144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x154659c1c10>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    data=TrainData, kind =\"count\",\n",
    "    x=\"Gender\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8183807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x15467aa04f0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    data=TrainData, kind =\"count\",\n",
    "    y=\"Dependents\", #hue=\"Loan_Status\"#, palette=\"ch:.25\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eff15fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x15465a727c0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    data=TrainData, kind =\"count\",\n",
    "    x=\"Self_Employed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f2a000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1545f9a1be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    data=TrainData, kind =\"count\",\n",
    "    y=\"Property_Area\", hue=\"Loan_Status\"#, palette=\"ch:.25\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a299e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1545f9f5eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    data=TrainData, kind =\"box\", y=\"ApplicantIncome\",\n",
    "    x=\"Self_Employed\", hue=\"Loan_Status\", col=\"Credit_History\"#, palette=\"ch:.25\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce204dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1545f81f250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#catplot is used\n",
    "sns.catplot(\n",
    "    data=TrainData, kind =\"box\",\n",
    "    x=\"LoanAmount\", y=\"Dependents\", \n",
    "    hue=\"Loan_Status\" \n",
    ")\n",
    "\n",
    "# When categories are harder to define, we will use binning methods.\n",
    "# Scroll below to binning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed58389",
   "metadata": {},
   "source": [
    "Identify missing data of both types, numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c79eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumericData = TrainData.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "TrainData_n = TrainData[NumericData]\n",
    "#print(TrainData_n, '\\n')\n",
    "\n",
    "CategoricData = TrainData.select_dtypes(include = ['object']).columns.tolist()\n",
    "TrainData_c = TrainData[CategoricData]\n",
    "#print(TrainData_c, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f641098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 12)\n",
      "(614, 12)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "print(TrainData.shape)\n",
    "TrainData.drop_duplicates(inplace=True)\n",
    "print(TrainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "13ef46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we try to figure out what kind of missing values are there. \n",
    "# ‚Äú0‚Äù, ‚ÄúNot Applicable‚Äù, ‚ÄúNA‚Äù, ‚ÄúNone‚Äù, ‚ÄúNull‚Äù, or ‚ÄúINF‚Äù all can mean that the value is missing.\n",
    "for feature in TrainData.columns:\n",
    "    res = list(set(TrainData[feature]))\n",
    "    #print(res)\n",
    "\n",
    "# Therefore, all missing values are np.nan or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "0ecd5510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n",
      "(614, 12)\n",
      "(480, 12)\n"
     ]
    }
   ],
   "source": [
    "# First Approach: removing tuples. We remove tuples only if the dataset is large enough, and the tuple has multiple missing values.\n",
    "\n",
    "print(TrainData.isnull().sum()) #returns np.na or None\n",
    "print(TrainData.shape)\n",
    "TrainData_nonull = TrainData.dropna(inplace=False)\n",
    "print(TrainData_nonull.shape)\n",
    "\n",
    "# Credit_History is the feature with the most missing tuples, but 50/641 is not significant enough to discard the feature entirely.\n",
    "# 480/641 tuples remain. That's only around 78.18% of data. \n",
    "# Around 21.8% of data tuples have missing values. This may not be the best approach. Once the classification models are completed, \n",
    "# we can test using both datasets and evaluate their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b92f9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Approach: Using conclusions from data visualization section, decide for each feature how to fill the missing values.\n",
    "# Gender: most_frequent (male), since there is a huge variance between the two.\n",
    "# Married: we can drop the 3 tuples, knowing, their effect over 614 tuples is not significant anyway.\n",
    "# Dependents: knn\n",
    "# Self-Employed: knn\n",
    "# LoanAmount: (normally distributed variable, since mean=342, median=360, mode=360) impute with mean\n",
    "# Loan_Amount_Term: impute with median\n",
    "# Credit_History: knn\n",
    "\n",
    "\n",
    "\n",
    "#TODO knn (after discretization and normalization)\n",
    "\n",
    "#TODO later, we can fill the missing values using a regression model. (if we have time, research)\n",
    "\n",
    "\n",
    "\n",
    "# Note: In regards to imputing missing data: \"Mean is most useful when the original data is not skewed, \n",
    "# while the median is more robust, not sensitive to outliers, and thus used when data is skewed.\n",
    "# \"It is worth mentioning that linear regression models are sensitive to outliers.\n",
    "# \"ùëò nearest neighbour imputation, which classifies similar records and put them together, can also be utilized. \n",
    "# A missing value is then filled out by finding first the ùëò records closest to the record with missing values. \n",
    "# Next, a value is chosen from (or computed out of) the ùëò nearest neighbours.\"\n",
    "# source: https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4\n",
    "# \"One thing to note here is that the KNN Imputer does not recognize text data values.\" We must discretize categorical features first.\n",
    "# \"Another critical point here is that the KNN Imptuer is a distance-based imputation method and it requires us to normalize our data. \n",
    "# Otherwise, the different scales of our data will lead the KNN Imputer to generate biased replacements for the missing values.\"\n",
    "# source: https://medium.com/@kyawsawhtoon/a-guide-to-knn-imputation-95e2dc496e\n",
    "# very IMPORTANT read, for later phases, on how to structure our preprocessing + predictors: (STACKING)\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f195bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MostFreqImputer = SimpleImputer(missing_values = np.NaN , strategy = 'most_frequent') #cat and num\n",
    "MeanImputer = SimpleImputer(missing_values = np.NaN , strategy = 'mean') #num\n",
    "MedianImputer = SimpleImputer(missing_values = np.NaN , strategy = 'median') #num\n",
    "#MedianCatImputer = SimpleImputer(missing_values = np.NaN , strategy = 'constant', fill_value=\"calc median for feature x\") #cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "dd93aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Gender: mode\n",
    "TrainData_Gender = np.array(TrainData['Gender']).reshape(-1, 1)\n",
    "MostFreqImputer.fit(TrainData_Gender)\n",
    "TrainData_Gender = MostFreqImputer.transform(TrainData_Gender)\n",
    "TrainData_Gender = TrainData_Gender.flatten()\n",
    "#TrainData['Gender'] = TrainData_Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "d5b4da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LoanAmount: mean\n",
    "TrainData_LoanA = np.array(TrainData['LoanAmount']).reshape(-1, 1)\n",
    "MeanImputer.fit(TrainData_LoanA)\n",
    "TrainData_LoanA = MeanImputer.transform(TrainData_LoanA)\n",
    "TrainData_LoanA = TrainData_LoanA.flatten()\n",
    "#print(TrainData_LoanA.shape)\n",
    "\n",
    "#TrainData['LoanAmount'] = TrainData_LoanA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5622b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614,)\n"
     ]
    }
   ],
   "source": [
    "# For Loan_Amount_Term: median\n",
    "TrainData_LoanT = np.array(TrainData['Loan_Amount_Term']).reshape(-1, 1)\n",
    "MedianImputer.fit(TrainData_LoanT)\n",
    "TrainData_LoanT = MedianImputer.transform(TrainData_LoanT)\n",
    "TrainData_LoanT = TrainData_LoanT.flatten()\n",
    "print(TrainData_LoanT.shape)\n",
    "#TrainData['Loan_Amount_Term'] = TrainData_LoanT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "25d98b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 12)\n",
      "(614, 12)\n"
     ]
    }
   ],
   "source": [
    "# For Married: drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba27cb",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "48e57694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender labels:  [0 1 2]\n",
      "['Female' 'Male' nan]\n",
      "Dependents labels:  [0 1 2 3 4]\n",
      "['0' '1' '2' '3+' nan]\n",
      "Self_Employed labels:  [0 1 2]\n",
      "['No' 'Yes' nan]\n",
      "Credit_History labels:  [0 1 2]\n",
      "[ 0.  1. nan]\n"
     ]
    }
   ],
   "source": [
    "# Dependents: knn\n",
    "# Self-Employed: knn\n",
    "# Credit_History: knn\n",
    "\n",
    "\n",
    "# KNN (TODO after discretization and normalization as discussed in the comments)\n",
    "\n",
    "# To find KNN between gender and loan_status, first use encoding to convert all categoric data into numeric data\n",
    "#Using LabelEncoder()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "genderencode = LabelEncoder()\n",
    "genderlabels = genderencode.fit_transform(TrainData['Gender'])\n",
    "#Replace each value in Gender column with corresponding genderlabels\n",
    "#replace each nonnumerical value with numerical value\n",
    "#print(genderlabels)\n",
    "unique = np.unique(genderlabels)\n",
    "print(\"Gender labels: \", unique)\n",
    "#unique = np.array(genderlabels)\n",
    "gender = print(genderencode.inverse_transform(unique))\n",
    "TrainDataNew_c = TrainData_c.copy()                                 \n",
    "TrainDataNew_c['Gender'] = TrainDataNew_c['Gender'].replace('Female', 0)\n",
    "TrainDataNew_c['Gender'] = TrainDataNew_c['Gender'].replace('Male', 1)\n",
    "TrainDataNew_c['Gender'] = TrainDataNew_c['Gender'].replace('nan', 2)\n",
    "#print(TrainDataNew_c['Gender'])\n",
    "\n",
    "dependentsencode = LabelEncoder()\n",
    "dependentslabels = dependentsencode.fit_transform(TrainData['Dependents'])\n",
    "unique = np.unique(dependentslabels)\n",
    "print(\"Dependents labels: \", unique)\n",
    "#unique = np.array(dependentslabels)\n",
    "print(dependentsencode.inverse_transform(unique))\n",
    "TrainDataNew_c['Dependents'] = TrainDataNew_c['Dependents'].replace('0', 0)\n",
    "TrainDataNew_c['Dependents'] = TrainDataNew_c['Dependents'].replace('1', 1)\n",
    "TrainDataNew_c['Dependents'] = TrainDataNew_c['Dependents'].replace('2', 2)\n",
    "TrainDataNew_c['Dependents'] = TrainDataNew_c['Dependents'].replace('3+', 3)\n",
    "TrainDataNew_c['Dependents'] = TrainDataNew_c['Dependents'].replace('nan', 4)\n",
    "#print(TrainDataNew_c['Dependents'])\n",
    "\n",
    "selfemployedencode = LabelEncoder()\n",
    "selfemployedlabels = selfemployedencode.fit_transform(TrainData['Self_Employed'])\n",
    "unique = np.unique(selfemployedlabels)\n",
    "print(\"Self_Employed labels: \", unique)\n",
    "#unique = np.array(selfemployedlabels)\n",
    "print(selfemployedencode.inverse_transform(unique))\n",
    "TrainDataNew_c['Self_Employed'] = TrainDataNew_c['Self_Employed'].replace('No', 0)\n",
    "TrainDataNew_c['Self_Employed'] = TrainDataNew_c['Self_Employed'].replace('Yes', 1)\n",
    "TrainDataNew_c['Self_Employed'] = TrainDataNew_c['Self_Employed'].replace('nan', 2)\n",
    "#print(TrainDataNew_c['Self_Employed'])\n",
    "\n",
    "credithistoryencode = LabelEncoder()\n",
    "credithistorylabels = credithistoryencode.fit_transform(TrainData['Credit_History'])\n",
    "unique = np.unique(credithistorylabels)\n",
    "print(\"Credit_History labels: \", unique)\n",
    "#unique = np.array(credithistorylabels)\n",
    "print(credithistoryencode.inverse_transform(unique))\n",
    "#Add to numeric table\n",
    "TrainDataNew_n = TrainData_n.copy() \n",
    "TrainDataNew_n['Credit_History'] = TrainDataNew_n['Credit_History'].replace('0.', 0)\n",
    "TrainDataNew_n['Credit_History'] = TrainDataNew_n['Credit_History'].replace('1.', 1)\n",
    "TrainDataNew_n['Credit_History'] = TrainDataNew_n['Credit_History'].replace('nan', 2)\n",
    "#print(TrainDataNew_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05b63a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term\n",
      "0           0.070489           0.000000         NaN          0.743590\n",
      "1           0.054830           0.036192    0.172214          0.743590\n",
      "2           0.035250           0.000000    0.082489          0.743590\n",
      "3           0.030093           0.056592    0.160637          0.743590\n",
      "4           0.072356           0.000000    0.191027          0.743590\n",
      "..               ...                ...         ...               ...\n",
      "609         0.034014           0.000000    0.089725          0.743590\n",
      "610         0.048930           0.000000    0.044863          0.358974\n",
      "611         0.097984           0.005760    0.353111          0.743590\n",
      "612         0.091936           0.000000    0.257598          0.743590\n",
      "613         0.054830           0.000000    0.179450          0.743590\n",
      "\n",
      "[614 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#divide into categorical and numerical data: DONE\n",
    "#plot nonnormalised categorical data on x axis\n",
    "#plot normalised numerical data on y axis\n",
    "#Normalise numerical data except Credit_History\n",
    "#MinMaxScaler was used because \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TrainDataNew_n = pd.DataFrame(TrainDataNew_n)\n",
    "normaliser_n = MinMaxScaler(feature_range = (0,1))\n",
    "exception = TrainDataNew_n.loc[:, TrainDataNew_n.columns!=\"Credit_History\"]\n",
    "normaldata_n = normaliser_n.fit_transform(exception)\n",
    "#print(normaldata_n)\n",
    "scaled = pd.DataFrame(normaldata_n, columns = exception.columns.values)\n",
    "print(scaled)\n",
    "#print(TrainDataNew_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "083cb583",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'value' must be an instance of str or bytes, not a float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4292\\1584980060.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Loan_Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2817\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2818\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2819\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2820\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2821\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4354\u001b[0m         \"\"\"\n\u001b[0;32m   4355\u001b[0m         \u001b[1;31m# Process **kwargs to handle aliases, conflicts with explicit kwargs:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4356\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4357\u001b[0m         \u001b[1;31m# np.ma.ravel yields an ndarray, not a masked array,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4358\u001b[0m         \u001b[1;31m# unless its argument is a masked array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_process_unit_info\u001b[1;34m(self, datasets, kwargs, convert)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;31m# Update from data if axis is already set but no unit is set yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2525\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhave_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2526\u001b[1;33m                 \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2527\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2528\u001b[0m             \u001b[1;31m# Return if no axis is set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mupdate_units\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1447\u001b[0m         \u001b[0mneednew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0mdefault\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\category.py\u001b[0m in \u001b[0;36mdefault_units\u001b[1;34m(data, axis)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# the conversion call stack is default_units -> axis_info -> convert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUnitData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\category.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\category.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;31m# OrderedDict just iterates over unique values in data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_isinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvertible\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[1;31m# this will only be called so long as convertible is True.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Downloads\\ANACONDA3\\lib\\site-packages\\matplotlib\\_api\\__init__.py\u001b[0m in \u001b[0;36mcheck_isinstance\u001b[1;34m(_types, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \"{!r} must be an instance of {}, not a {}\".format(\n\u001b[0;32m     95\u001b[0m                     \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'value' must be an instance of str or bytes, not a float"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Gender vs Loan_Status\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(TrainData['Gender'], TrainData['Loan_Status'], marker= '*',s=100,edgecolors='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a290e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e59e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Approach: Flagging\n",
    "# Some data is missing not at random (MNAR). This means that the data is probably missing due to the feature itself.\n",
    "# One example would be loan amount. If it is too high, people might refuse to say.\n",
    "# Some data is missing at random. This means that the data is probably missing because of another measured variable.\n",
    "# An example would be self-employment. Those working in rural areas such as farms might be trivially self-employed. We might\n",
    "# trivially replace all the missing values with \"No\".\n",
    "# Observing the data, credit history is the variable with most missing values. This may be due to applicants not being able\n",
    "# to prove their credit history.\n",
    "# In this case, data is missing completely at random (MCAT).\n",
    "# We mention this approach, even though it may not be applicable to our project, because it is important to remember\n",
    "# that even missing values can provide valuable information, which we may get rid of by imputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bef232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"example record: \", TrainData.values[0]) #example of record with missing num values\n",
    "print(\"example record: \", TrainData.values[23]) #example of record with missing cat values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e2fc1e",
   "metadata": {},
   "source": [
    "### Handle Noisy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c1908",
   "metadata": {},
   "source": [
    "#### Binning By pd.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bedde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin by Applicant Income, Coapplicant Income, Loan Amount\n",
    "print(TrainData['ApplicantIncome'].describe())\n",
    "#ApplicantIncomeCut = pd.cut(TrainData.iloc[:, 5], 4)\n",
    "#print(ApplicantIncomeCut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins = 10\n",
    "ApplicantIncomeBinSize = (81000 - 150)/Bins\n",
    "print(pd.cut(TrainData['ApplicantIncome'], Bins, precision = 0).value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74211fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData['ApplicantIncome_Bin'] = pd.cut(TrainData['ApplicantIncome'], Bins, labels = False)\n",
    "#print(TrainData.head())                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6291685",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainData['CoapplicantIncome'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb86047",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainData['LoanAmount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9181ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When categories are harder to define, we will use binning methods.\n",
    "\n",
    "#TODO move this to after Binning and (maybe) change up the binned vars\n",
    "# sns.scatterplot( data=TrainData,\n",
    "#     x=\"CoapplicantIncome\", y=\"LoanAmount\", hue=\"Loan_Status\" #col=\"Loan_Status  \", style=\"smoker\", size=\"size\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c5243",
   "metadata": {},
   "source": [
    "#### Binning By Feature Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feccb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing\n",
    "from feature_engine.discretisation import EqualWidthDiscretiser\n",
    "#Bin by Applicant Income, Coapplicant Income, Loan Amount\n",
    "ApplicantIncomeFE = EqualWidthDiscretiser(bins=10, return_object = True, return_boundaries = True)\n",
    "#ApplicantIncomeFE.fit(TrainData)\n",
    "#ApplicantIncomeFE.transform(TrainData)[\"ApplicantIncome_b\"].value_counts()\n",
    "#ApplicantIncomeFE = EqualWidthDiscretiser()\n",
    "#print(ApplicantIncomeFE)\n",
    "ApplicantIncomeFE.fit(TrainData)\n",
    "ApplicantIncomeFE.transform(TrainData)[\"ApplicantIncome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18229b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoapplicantIncomeFE = EqualWidthDiscretiser(bins=10, return_object = True, return_boundaries = True)\n",
    "CoapplicantIncomeFE.fit(TrainData)\n",
    "CoapplicantIncomeFE.transform(TrainData)[\"CoapplicantIncome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanAmountFE = EqualWidthDiscretiser(bins=10, return_object = True, return_boundaries = True)\n",
    "LoanAmountFE.fit(TrainData)\n",
    "LoanAmountFE.transform(TrainData)[\"LoanAmount\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When categories are harder to define, we will use binning methods.\n",
    "\n",
    "#TODO move this to after Binning and (maybe) change up the binned vars\n",
    "# sns.scatterplot( data=TrainData,\n",
    "#     x=\"CoapplicantIncome\", y=\"LoanAmount\", hue=\"Loan_Status\" #col=\"Loan_Status  \", style=\"smoker\", size=\"size\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f31693",
   "metadata": {},
   "source": [
    "#### Binning By KBinsDiscretizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad09663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default bins\n",
    "TrainDataAmounts = TrainData[NumericData]\n",
    "print(TrainDataAmounts)\n",
    "TrainDataEqual = KBinsDiscretizer(n_bins = 10, strategy = 'uniform', encode = 'ordinal')\n",
    "n = TrainDataEqual.fit(TrainDataAmounts)\n",
    "print(n.bin_edges_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2333651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default bins\n",
    "TrainDataAmounts = TrainData[NumericData]\n",
    "print(TrainDataAmounts)\n",
    "TrainDataEqual = KBinsDiscretizer(n_bins = 10, strategy = 'quantile', encode = 'ordinal')\n",
    "n = TrainDataEqual.fit(TrainDataAmounts)\n",
    "print(n.bin_edges_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When categories are harder to define, we will use binning methods.\n",
    "\n",
    "#TODO move this to after Binning and (maybe) change up the binned vars\n",
    "# sns.scatterplot( data=TrainData,\n",
    "#     x=\"CoapplicantIncome\", y=\"LoanAmount\", hue=\"Loan_Status\" #col=\"Loan_Status  \", style=\"smoker\", size=\"size\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2146a",
   "metadata": {},
   "source": [
    "### Data Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant data\n",
    "TrainData.corr()\n",
    "# TODO move this to after discretization, and check it with loan_status. if weakly correlated with loan_status, you can remove the feature\n",
    "# TODO we can carry out dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0697f8",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14e5d3",
   "metadata": {},
   "source": [
    "#### Using Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze their impact, then decide whether to remove the outliers\n",
    "# We can also use regression to get standardized_residuals and analyze the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ecad1",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da14e98",
   "metadata": {},
   "source": [
    "### Single Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = TrainData['ApplicantIncome']\n",
    "y = TrainData['ApplicantIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression of ApplicantIncome and LoanAmount\n",
    "ApplicantIncomeMean = sum(TrainData['ApplicantIncome'])/614\n",
    "LoanAmountMean = sum(TrainData['LoanAmount'])/614\n",
    "print(\"ApplicantIncomeMean: \", ApplicantIncomeMean,'\\n')\n",
    "print(\"LoanAmountMean: \", LoanAmountMean, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxtotal = 0\n",
    "xytotal = 0\n",
    "for i in range(614):\n",
    "    xdiff = (x[i] - ApplicantIncomeMean)**2\n",
    "    #print(\"x:\", xdiff)\n",
    "    xxtotal = xxtotal + xdiff\n",
    "    ydiff = (x[i] - ApplicantIncomeMean) * (y[i] - LoanAmountMean)\n",
    "    #print(\"y:\", ydiff)\n",
    "    xytotal = xytotal + ydiff\n",
    "\n",
    "#Sumxx = np.sum(xdiff, axis = 0, keepdims = True)\n",
    "#Sumxy = np.sum(ydiff, axis = 0, keepdims = True)\n",
    "print(\"SSx: \", \"{0: .3f}\".format(xxtotal), '\\n')\n",
    "print(\"SPxy: \", \"{0: .3f}\".format(xytotal), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = xytotal / xxtotal\n",
    "print(\"Slope: \", \"{0: .3f}\".format(slope), '\\n')\n",
    "intercept = LoanAmountMean - (slope * ApplicantIncomeMean)\n",
    "print(\"Intercept: \", \"{0: .3f}\".format(intercept), '\\n')\n",
    "print(\"y = \", slope, \"x + \", intercept, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "residual = []\n",
    "#residual = predicted - actual\n",
    "for p in range(len(x)):\n",
    "    #predicted = slope * (x[p]) + intercept\n",
    "    predicted.append(slope * (x[p]) + intercept)\n",
    "    residual.append(predicted[p] - y[p])\n",
    "    #print(\"x:\", x[p],\" y:\", y[p], \"predicted:\", \"{0: .2f}\".format(predicted[p]), \"residual:\", \"{0: .2f}\".format(residual[p]))\n",
    "\n",
    "#residual = predicted[p] - y[p]\n",
    "#residual.append(predicted - y[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from numpy.linalg import eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dee99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x, y, color = \"black\", alpha = 0.5, s = 10)\n",
    "plt.plot(x, predicted, color = \"red\")\n",
    "plt.margins(x = 0, y = 0) \n",
    "plt.grid()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a01db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#DOWNLOAD PLOTTOOLS VIA CMD PROMPT:::import plottools\n",
    "\n",
    "standardised_residuals = residual / np.std(residual)\n",
    "#print(standardised_residuals)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x, residual, color = \"orange\", alpha = 0.5 , s = 10)\n",
    "plt.grid()\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Loan Amount')\n",
    "#plt.margins(x = 0, y = 0) \n",
    "plt.axis('auto')\n",
    "plt.show()\n",
    "\n",
    "#Sample points from the above graph \n",
    "def select_subset(seq, size):\n",
    "    return seq[:size]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "Xi_sample = [select_subset(x, 100)]\n",
    "Yi_sample = [select_subset(residual, 100)]\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Loan Amount')\n",
    "plt.scatter(Xi_sample, \n",
    "            Yi_sample, \n",
    "            marker=\"o\", color=\"blue\", alpha = 0.5 , s = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd801515",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig,ax = plt.subplots(6,6)\n",
    "ax.plot(x, residual)\n",
    "ax_zoom = plottools.zoom_axes(fig,ax,[0,20000],[-1.0,-0.8],[40000,-0.8],[40000,-0.8])\n",
    "ax_zoom.plot(x,y)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c6c9c",
   "metadata": {},
   "source": [
    "### Multilinear Regression : Dependents and Property and Income VS Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = TrainData[['Dependents','Property_Area','ApplicantIncome']]\n",
    "X = TrainData[['ApplicantIncome', 'CoapplicantIncome']]\n",
    "Y = TrainData['LoanAmount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55eb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174753d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiReg = linear_model.LinearRegression()\n",
    "MultiReg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanPredicted = MultiReg.predict([[1000, 1300]])\n",
    "print(LoanPredicted)\n",
    "LoanPredicted = MultiReg.predict([[2000, 2300]])\n",
    "print(LoanPredicted)\n",
    "LoanPredicted = MultiReg.predict([[3000, 3300]])\n",
    "print(LoanPredicted)\n",
    "LoanPredicted = MultiReg.predict([[4000, 4300]])\n",
    "print(LoanPredicted)\n",
    "LoanPredicted = MultiReg.predict([[5000, 5300]])\n",
    "print(LoanPredicted)\n",
    "LoanPredicted = MultiReg.predict([[6000, 6300]])\n",
    "print(LoanPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce3e78",
   "metadata": {},
   "source": [
    "### Clustering By KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a885a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataK = pd.read_csv(\"Train Data.csv\", delimiter = ',', header = 0, index_col = \"Loan_ID\")\n",
    "print(TrainDataK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeanEncoder = LabelEncoder()\n",
    "\n",
    "KMeanEncoder.fit(TrainDataK[\"LoanAmount\"])\n",
    "TrainDataK[\"LoanAmount\"] = KMeanEncoder.transform(TrainDataK[\"LoanAmount\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Gender\"])\n",
    "TrainDataK[\"Gender\"] = KMeanEncoder.transform(TrainDataK[\"Gender\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Married\"])\n",
    "TrainDataK[\"Married\"] = KMeanEncoder.transform(TrainDataK[\"Married\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Dependents\"])\n",
    "TrainDataK[\"Dependents\"] = KMeanEncoder.transform(TrainDataK[\"Dependents\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Education\"])\n",
    "TrainDataK[\"Education\"] = KMeanEncoder.transform(TrainDataK[\"Education\"])\n",
    "\n",
    "KMeanEncoder.fit(TrainDataK[\"Self_Employed\"])\n",
    "TrainDataK[\"Self_Employed\"] = KMeanEncoder.transform(TrainDataK[\"Self_Employed\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"ApplicantIncome\"])\n",
    "TrainDataK[\"ApplicantIncome\"] = KMeanEncoder.transform(TrainDataK[\"ApplicantIncome\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"CoapplicantIncome\"])\n",
    "TrainDataK[\"CoapplicantIncome\"] = KMeanEncoder.transform(TrainDataK[\"CoapplicantIncome\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Loan_Amount_Term\"])\n",
    "TrainDataK[\"Loan_Amount_Term\"] = KMeanEncoder.transform(TrainDataK[\"Loan_Amount_Term\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Credit_History\"])\n",
    "TrainDataK[\"Credit_History\"] = KMeanEncoder.transform(TrainDataK[\"Credit_History\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Property_Area\"])\n",
    "TrainDataK[\"Property_Area\"] = KMeanEncoder.transform(TrainDataK[\"Property_Area\"])\n",
    "KMeanEncoder.fit(TrainDataK[\"Loan_Status\"])\n",
    "TrainDataK[\"Loan_Status\"] = KMeanEncoder.transform(TrainDataK[\"Loan_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303be4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeanClusters = KMeans(n_clusters = 5).fit(TrainDataK.iloc[:, :])\n",
    "print(KMeanClusters.labels_, '\\n')\n",
    "print(KMeanClusters.cluster_centers_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8cf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#DOWNLOAD PLOTTOOLS VIA CMD PROMPT:::import plottools\n",
    "XDep = TrainDataK['LoanAmount']\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(XDep, KMeanClusters.labels_, color = \"red\", alpha = 0.5 , s = 10)\n",
    "#plt.scatter(XDep, KMeanClusters.cluster_centers_, color = \"black\", alpha = 0.5 , s = 10)\n",
    "plt.grid()\n",
    "plt.xlabel('Dependent var')\n",
    "plt.ylabel('Clusters')\n",
    "#plt.margins(x = 0, y = 0) \n",
    "plt.axis('auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762ecb4",
   "metadata": {},
   "source": [
    "### Clustering By KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed171a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([[1, 2], [1, 4], [1, 0],\n",
    "                [4, 2], [4, 4], [4, 0]])\n",
    "kmedoids = KMedoids(n_clusters=2, random_state=0).fit(X)\n",
    "kmedoids.labels_\n",
    "array([0, 0, 0, 1, 1, 1])\n",
    "kmedoids.predict([[0,0], [4,4]])\n",
    "array([0, 1])\n",
    "kmedoids.cluster_centers_\n",
    "array([[1., 2.],\n",
    "       [4., 2.]])\n",
    "kmedoids.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3ced9",
   "metadata": {},
   "source": [
    "## the correlations and their visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = TrainData.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following is the visualization of the correlation matrix which shows the strength of the relation between each 2 variables\n",
    "# you will find that we did not visualize the variable with itself because it will always be (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome\", y=\"CoapplicantIncome\")\n",
    "# negative weak relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f565bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome\", y=\"LoanAmount\")\n",
    "#positive medium relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome\", y=\"Loan_Amount_Term\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721c860",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome\", y=\"Credit_History\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome\", y=\"ApplicantIncome_Bin\")\n",
    "#very strong positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afca71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"CoapplicantIncome\", y=\"ApplicantIncome\")\n",
    "#  weak negative relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2097bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"CoapplicantIncome\", y=\"LoanAmount\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"CoapplicantIncome\", y=\"Loan_Amount_Term\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f01e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"CoapplicantIncome\", y=\"Credit_History\")\n",
    "# no relation(<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca773049",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"CoapplicantIncome\", y=\"ApplicantIncome_Bin\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fa8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"LoanAmount\", y=\"ApplicantIncome\")\n",
    "# medium positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"LoanAmount\", y=\"CoapplicantIncome\")\n",
    "# weak positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"LoanAmount\", y=\"Loan_Amount_Term\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"LoanAmount\", y=\"Credit_History\")\n",
    "#no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"LoanAmount\", y=\"ApplicantIncome_Bin\")\n",
    "# medium positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fb5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Loan_Amount_Term\", y=\"ApplicantIncome\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Loan_Amount_Term\", y=\"CoapplicantIncome\")\n",
    "#no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e809c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Loan_Amount_Term\", y=\"LoanAmount\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Loan_Amount_Term\", y=\"Credit_History\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Loan_Amount_Term\", y=\"ApplicantIncome_Bin\")\n",
    "# no relation(<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b02675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Credit_History\", y=\"ApplicantIncome\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d985543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Credit_History\", y=\"CoapplicantIncome\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Credit_History\", y=\"LoanAmount\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5dd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Credit_History\", y=\"Loan_Amount_Term\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"Credit_History\", y=\"ApplicantIncome_Bin\")\n",
    "# no relation (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome_Bin\", y=\"ApplicantIncome\")\n",
    "# strong positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome_Bin\", y=\"CoapplicantIncome\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeba0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome_Bin\", y=\"LoanAmount\")\n",
    "#medium positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome_Bin\", y=\"Loan_Amount_Term\")\n",
    "# no relation (<-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=TrainData, x=\"ApplicantIncome_Bin\", y=\"Credit_History\")\n",
    "# no relation (<0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
